# BLOOM

## ğŸ”¹ Nom du modÃ¨le
BLOOM (BigScience Large Open-science Open-access Multilingual Language Model)

## ğŸ”¹ Type
LLM (Large Language Model)

## ğŸ”¹ Organisation / DÃ©veloppeur
BigScience project (initiative collaborative pilotÃ©e par Hugging Face et plusieurs chercheurs du monde entier, dont des franÃ§ais)

## ğŸ”¹ Date de sortie
Juillet 2022

## ğŸ”¹ TÃ¢ches rÃ©alisÃ©es
- GÃ©nÃ©ration de texte multilingue
- Traduction
- RÃ©sumÃ© automatique
- RÃ©ponses Ã  des questions
- Vulgarisation de texte scientifique
- ComplÃ©tion de texte, reformulation

## ğŸ”¹ Exemples concrets d'usage
- Vulgarisation scientifique en franÃ§ais
- Traduction anglais â†” franÃ§ais
- RÃ©sumÃ©s de documents techniques
- IntÃ©gration dans des chatbots open-source
- Projets Ã©ducatifs ou Ã©thiques basÃ©s sur un modÃ¨le libre

## ğŸ”¹ Mode d'accÃ¨s
- Totalement open-source
- Utilisable directement via Hugging Face ğŸ¤—
- ModÃ¨les disponibles de 560M Ã  176B paramÃ¨tres
- Peut Ãªtre exÃ©cutÃ© sur Google Colab, localement ou sur des serveurs cloud
ğŸ”— Lien : https://huggingface.co/bigscience/bloom

## ğŸ”¹ Exemple de gÃ©nÃ©ration (Prompt + RÃ©sultat)
**Prompt :**
"Explique simplement ce que sont les autoencodeurs variationnels."

**RÃ©sultat (BLOOM) :**
"Les autoencodeurs variationnels sont des modÃ¨les d'intelligence artificielle qui apprennent Ã  reprÃ©senter les donnÃ©es de maniÃ¨re plus simple. Ensuite, ils peuvent utiliser cette reprÃ©sentation pour gÃ©nÃ©rer de nouvelles donnÃ©es qui ressemblent Ã  ce qu'ils ont appris."

## ğŸ”¹ Lien vers dÃ©mo ou code
- [Page Hugging Face officielle](https://huggingface.co/bigscience/bloom)
- [Demo dans le Hugging Face Inference API](https://huggingface.co/bigscience/bloom)
- [Notebooks de test Colab](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling_from_scratch.ipynb)

## ğŸ”¹ Commentaires et remarques
âœ… TrÃ¨s bon support du franÃ§ais (prÃ©-entraÃ®nÃ© dessus)
âœ… Open-source et transparent
âœ… IdÃ©al pour projets Ã©ducatifs, scientifiques et responsables
âŒ Moins puissant que GPT-4 ou Claude sur les tÃ¢ches complexes
âŒ Parfois un peu rigide ou gÃ©nÃ©rique dans ses rÃ©ponses
âŒ NÃ©cessite un bon prompt engineering pour vulgariser efficacement 